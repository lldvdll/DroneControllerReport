\section{Introduction}
We study the autonomous navigation of an underactuated system, planar drone ($x, y, \theta$) controlled by two upward thrusts $(T_1, T_2)$. Since lateral motion requires prior rotation, actions exhibit delayed kinematic effects that physics-based controllers often struggle to manage. To address this, we employ Reinforcement Learning (RL) to derive anticipatory policies capable of momentum management and collision avoidance for sequential target acquisition within hard boundaries. \cite{Mair2020} We compare two RL approaches. \textbf{REINFORCE}, a continuous policy gradient method using a shallow neural network, and \textbf{SARSA}, a discrete value-based method using tabular state-action values. We demonstrate that while REINFORCE only achieves temporary hover stability, SARSA converges to a robust boundary-aware policy which outperforms a heuristic controller in target acquisition by 28\% and path efficiency by 24\%.